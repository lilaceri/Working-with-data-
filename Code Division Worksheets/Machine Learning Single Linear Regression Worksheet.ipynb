{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Predicting student scores - not checked/finished\n",
    "---\n",
    "\n",
    "In previous worksheets, we have done a simple linear regression using the stats.linregress function. Today we are going to take it one step further and train Python to predict future test scores. The way we will do this is by splitting our dataset into a training set (80%) and a test set (20%). We will also split the datasets into our x and y. Using the training set, the computer will run a linear regression (like what we did in Python and R) and then learn to predict the student scores. We will then test how well it can predict by giving the test dataset's X to it, and comparing it's predictions with the actual student scores (Y).  \n",
    "\n",
    "To do this, we will be using a new library: **sklearn** as well as:\n",
    "* pandas  \n",
    "* numpy  \n",
    "* seaborn  \n",
    "* matplotlib.pyplot  \n",
    "* scipy.stats  \n",
    "\n",
    "`sklearn` has many associated packages related to machine learning but the ones we'll be using today are:  \n",
    "\n",
    "`from sklearn.model_selection import train_test_split`   \n",
    "`from sklearn.linear_model import LinearRegression`  \n",
    "`from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error`  \n",
    "\n",
    "Go ahead and load all the required packages below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Today we will be using a simple dataset of student scores\n",
    "---\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/lilaceri/Working-with-data-/main/Data%20Sets%20for%20code%20divisio/student_scores.csv\"\n",
    "\n",
    "It contains 2 variables, `Hours` studied and test `Scores`. \n",
    "\n",
    "Read in the data and have a look it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - Clean the data\n",
    "---\n",
    "\n",
    "* check data for null values and remove if necessary\n",
    "* check data for outliers using a boxplot\n",
    "* remove outliers if necessary (you can use the function you created in the Correlation and Models worksheet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 - visualise linear relationship\n",
    "---\n",
    "\n",
    "Using seaborns regplot, visualise the relationship of the variables \n",
    "\n",
    "* use `sns.regplot()`\n",
    "* split data into x (hours) and y (scores) variables\n",
    "\n",
    "*(this is the same as using linregress and matplotlib to create a scatter with line of best fit)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 - check for normality \n",
    "---\n",
    "\n",
    "* using describe() - check if the mean and median is similar \n",
    "* using seaborns distplot, check the shape of the data \n",
    "\n",
    "Does it look roughly gaussian in shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 - Check the correlation\n",
    "---\n",
    "\n",
    "* create a correlation matrix using the corr() function \n",
    "* create a heatmap using `sns.heatmap()` \n",
    "\n",
    "Are they highly correlated (close to 1 or -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5 - reshape x and y \n",
    "---\n",
    "\n",
    "Earlier we split our data into x and y. Currently if you look at their shape, they will be (25, ). In order to do the linear regression, they need to have the shape (25, 1). As our data is 1 dimensional we need to turn it into 2 dimensional data so that sklearn can understand it. We need to tell it to focus on using the data as a column, rather than a row: (-1,1) means not a row but a column. \n",
    "\n",
    "\n",
    "To transform our x and y datasets into a shape that sklearn can understand we will use numpy to reshape the data. \n",
    "\n",
    "This can be done using `np.array(variable).reshape(-1, 1)`  \n",
    "\n",
    "* reshape the x and y variables using `np.array(variable).reshape(-1, 1)` \n",
    "* check the shape of each one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6 - splitting the data \n",
    "---\n",
    "\n",
    "In order to tell how accurately our model can predict we will need to test it. To do this we will split off 20% of the data to later use to test our models predictions. The remaining 80% will be used to train (teach) the computer how to predict. \n",
    "\n",
    "We will therefore turn our x and y variables into 4 datasets: x_train, y_train, x_test and y_test.\n",
    "\n",
    "To do this use:\n",
    "\n",
    "`x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)`\n",
    "\n",
    "* the `test_size` parameter is how big you want your testing set to be, in this case 0.2 = 20% of the original data  \n",
    "* the `random_state` parameter is used as a placeholder for that specific split. Without it, everytime the code was run, the test and train variables would be split differently. The specific number doesnt matter, but sklearn will save that specific split of the data into that number of random_state\n",
    "\n",
    "**Split your data into training and testing sets**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7 - fit the data and perform linear regression\n",
    "---\n",
    "\n",
    "We are now going to perform a linear regression on our training data, so that we can fit our model to the training data. \n",
    "\n",
    "To do this:\n",
    "\n",
    "1. set the `LinearRegression()` function into a variable called `lin_reg` \n",
    "2. use `lin_reg.fit(x_train, y_train)` to fit the model to the data \n",
    "\n",
    "Similar to `stats.linregress` we can use the intercept and coefficents from this function to plot a line of best fit..  \n",
    "* the slope is accessed using: `lin_reg.coef_`\n",
    "* the intercept is accessed using: `lin_reg.intercept_` \n",
    "\n",
    "3. plot a scatter plot using matplotlib\n",
    "4. add a line of best fit using the slope and intercept from your regression\n",
    "5. compare it to the regplot you made in Ex 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8 - make some predictions\n",
    "---\n",
    "\n",
    "Now that we've created a model using our training data, we can test it using the test data. We can attempt to predict student scores (y) from how many hours of study has been done. We can then compare these to the real actual student scores.\n",
    "\n",
    "* create a new variable to store your predicted y values in \n",
    "* use `lin_reg.predict(dataset)` to predict using your x_test dataset \n",
    "* compare your predicted y values with your actual y values (y_test) - are they similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9 - How good is our model at predicting?\n",
    "---\n",
    "\n",
    "As mentioned in previous worksheets, r squared (r^2) measures how much of the variance of the y can be explained by x. A higher r^2 means that our model is predicting y well. \n",
    "\n",
    "* using `r2_score(y_predictions, y_test)` see how well your model is predicting y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10 - evaluating the model further\n",
    "---\n",
    "\n",
    "r^2 isnt the only way to evaluate our model..\n",
    "\n",
    "* Mean Absolute Error (MAE) - tells us how big the error in our model is, so how far away the actual values are from the predicted values  \n",
    "    `mean_absolute_error(test, predictions)`  \n",
    "    \n",
    "* Root Mean Squared Error (RMSE) - tells us the mean difference between the predicted values and the actual values  \n",
    "    `metrics.mean_squared_error(test, predictions, squared = False)` \n",
    "Both these measures of error tell us a similar thing, \n",
    "\n",
    "The bigger the spread of the data and the smaller the dataset, the higher the error.\n",
    "\n",
    "\n",
    "**Calculate the MAE and RMSE for your model using the y test and prediction values and evaluate how good your model is** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
