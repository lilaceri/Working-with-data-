{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Filtering_and_searching_worksheet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNIUO4xHNBkmdkGjPs+8Caa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lilaceri/Working-with-data-/blob/main/Filtering_and_searching_worksheet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CVoh0pMzW0l"
      },
      "source": [
        "# Filtering and Searching \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "In order to effectively analyse a dataset, often we need to prepare it first. \n",
        "Before a dataset is ready to be analysed we might need to:  \n",
        "\n",
        "* sort the data (can be a series or dataframe)  \n",
        "* remove any NaN values or drop NA values   \n",
        "* remove duplicate records (identical rows)  \n",
        "* normalise the dataframe  \n",
        "\n",
        "## Sorting the data  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Typically we want to sort data by the values in one or more columns in the dataframe  \n",
        "\n",
        "To sort the dataframe by series we use the pandas function **sort_values()** \n",
        "\n",
        "* by default sorts in ascending order     \n",
        "* Sorting by a single column\n",
        "  * `df.sort_values(\"Make\") `\n",
        "* Sorting by multiple columns \n",
        "  * `df.sort_values(by = [\"Model\", \"Make\"])[[\"Make\", \"Model\"]] `\n",
        "    * this sorts by make \n",
        "  * `df.sort_values(by = [\"Model\", \"Make\"])[[\"Model\", \"Make\"]]`\n",
        "    * this sorts by model \n",
        "* Sorting in *descending* order\n",
        "  * `df.sort_values(by = \"Make\", ascending = False)`\n",
        "  * `df.sort_values(by = [\"Make\", \"Model\"], ascending = False)[[\"Make\", \"Model\"]]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANKknIx8E-hN"
      },
      "source": [
        "### Exercise 1 - get data, sort by happiness score \n",
        "---\n",
        "\n",
        "\n",
        "1. import pandas library\n",
        "2. read excel file on Happiness Data from this link: https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\n",
        "3. display first 5 rows of data  \n",
        "\n",
        "The data is currently sorted by Happiness Rank...\n",
        "4. sort the data by happiness score in ascending order\n",
        "5. display sorted table\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkvFGvJtHXiH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_iomqRTH8LA"
      },
      "source": [
        "### Exercise 2 - sort by multiple columns, display the first 5 rows \n",
        "---\n",
        "\n",
        "1. Sort the data by economy (GDP) and health in ascending order \n",
        "2. Sort the data by health and economy in ascending order\n",
        "3. Display the first 5 rows of sorted data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7XalX7OK0u-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfQ3cys4LHNc"
      },
      "source": [
        "### Exercise 3 - sorting in descending order \n",
        "---\n",
        "1. sort the data by family in descending order \n",
        "2. sort the data by freedom and trust in the government in descending order \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3haPVvX7MCom"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqnAoELjMDs7"
      },
      "source": [
        "## Removing NaN/Dropping NA values \n",
        "---\n",
        "* check for NA/NaN/missing values across dataframe (returns True if NA values exist)\n",
        "  * `df.isnull().values.any()`\n",
        "* check for NA/NaN/missing values in specific column\n",
        "  * `df[\"Make\"].isnull().values.any()`\n",
        "* drop NA/NaN values from all rows \n",
        "  * `df.dropna()`\n",
        "* drop NA/NaN values from specific columns\n",
        "  * `df.dropna(subset = [\"make\", \"model\"])`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC65hEZGOKNL"
      },
      "source": [
        "### Exercise 4 - checking for null values \n",
        "---\n",
        "\n",
        "1. read in housing in london csv from this link: https://github.com/lilaceri/Working-with-data-/blob/24de902f057bb60b70b8272f39dd9a29a8853950/Data%20Sets%20for%20code%20divisio/housing_in_london_yearly_variables.csv?raw=true \n",
        "2. check if any NA values exist in the dataframe \n",
        "3. use df.info() to see which columns have null entries (*hint if the non-null count is less than total entries, column contains missing/NA entries*)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRBLm_bJVItu"
      },
      "source": [
        "### Exercise 5 - removing null values \n",
        "---\n",
        "\n",
        "1. remove rows with NA values for life satisfaction\n",
        "2. remove all NA values across whole dataframe "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjZJNIC3QObK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui8HF5z8SiK8"
      },
      "source": [
        "## Dropping duplicates\n",
        "---\n",
        "\n",
        "* To remove identical rows based on all columns\n",
        "  * `df.drop_duplicates()`\n",
        "* To remove rows of duplicate entries in a specified column\n",
        "  * `df.drop_duplicates(subset = ['Make'])`\n",
        "* Multiple columns\n",
        "  * `df.drop_duplicates(subset = ['Make', 'Model'])`\n",
        "* by default, it keeps the first instance, to keep last instance:\n",
        "  * `df.drop_duplicates(keep='last')`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2Qf6uMxSb5t"
      },
      "source": [
        "### Exercise 6 - Removing duplicate entries \n",
        "---\n",
        "\n",
        "remove duplicate area entries keeping first instance so dataframe only contains rows from 1999-12-*01* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ8T0tYVQj74"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHU4-ADHU4eq"
      },
      "source": [
        "### Exercise 7 - preparing dataset for normalisation \n",
        "---\n",
        "1. read covid vaccination data from the by_country sheet from this link : https://github.com/lilaceri/Working-with-data-/blob/342abab10d93c4bf23b5c55a50f189f12a137c5f/Data%20Sets%20for%20code%20divisio/Covid%20Vaccination%20Data.xlsx?raw=true\n",
        "2. use .info() to find out which columns have missing values\n",
        "3. remove all rows with missing data in the total_vaccination column\n",
        "4. find median vaccinations per hundred \n",
        "5. display the mean vaccinations per hundred for each country in descending order\n",
        "6. find the range of total_vaccinations across the dataframe \n",
        "\n",
        "\n",
        "Output:  \n",
        "1. dataframe is saved in a variable\n",
        "2. \n",
        "```\n",
        "RangeIndex: 14994 entries, 0 to 14993\n",
        "Data columns (total 15 columns):\n",
        "    Column                               Non-Null Count  Dtype         \n",
        "                                \n",
        " 0   country                              14994 non-null  object        \n",
        " 1   iso_code                             14994 non-null  object        \n",
        " 2   date                                 14994 non-null  datetime64[ns]\n",
        " 3   total_vaccinations                   9011 non-null   float64       \n",
        " 4   people_vaccinated                    8370 non-null   float64       \n",
        " 5   people_fully_vaccinated              6158 non-null   float64       \n",
        " 6   daily_vaccinations_raw               7575 non-null   float64       \n",
        " 7   daily_vaccinations                   14796 non-null  float64       \n",
        " 8   total_vaccinations_per_hundred       9011 non-null   float64       \n",
        " 9   people_vaccinated_per_hundred        8370 non-null   float64       \n",
        " 10  people_fully_vaccinated_per_hundred  6158 non-null   float64       \n",
        " 11  daily_vaccinations_per_million       14796 non-null  float64       \n",
        " 12  vaccines                             14994 non-null  object        \n",
        " 13  source_name                          14994 non-null  object        \n",
        " 14  source_website                       14994 non-null  object        \n",
        "dtypes: datetime64[ns](1), float64(9), object(5)\n",
        "memory usage: 1.7+ MB\n",
        "```\n",
        "3. 9011 rows × 15 columns\n",
        "4. 7.78\n",
        "5. \n",
        "```\n",
        "country\n",
        "Gibraltar       72.172462\n",
        "Maldives        51.276087\n",
        "Israel          48.931008\n",
        "Seychelles      48.233333\n",
        "Aruba           42.155000\n",
        "                  ...    \n",
        "Guinea           0.677000\n",
        "Sierra Leone     0.530000\n",
        "Namibia          0.317143\n",
        "South Africa     0.261667\n",
        "Albania          0.080000\n",
        "Name: people_vaccinated_per_hundred, Length: 104, dtype: float64\n",
        "```\n",
        "6. 275338000.0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQRCan65U4Gp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ_tQG_3WBXn"
      },
      "source": [
        "## Normalising Data  \n",
        "When we normalise data, we remodel a numeric column in a dataframe to be on a standard scale (0 or 1).   \n",
        "For example if we had a column of BMI scores, we could normalise that column so that all scores greater than or equal to 25 were recoded to the value 1 (bad) and all scores less than 25 were recoded to 0 (good).  \n",
        "\n",
        "For example:  \n",
        "\n",
        "` def normalise_bmi(df):`       \n",
        "> `if df['bmi'] >= 25:`  \n",
        "> >  `return 1`   \n",
        "\n",
        ">`else`:  \n",
        "> >`return 0`  \n",
        "\n",
        "`df[\"bmi\"] = df.apply(normalise, axis=1)`    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8yHJH706Cd9"
      },
      "source": [
        "### Exercise 8 - normalise daily vaccinations \n",
        "\n",
        "1. find the median daily vaccinations per 1 million \n",
        "2. write a function to normalise daily vaccinations per 1 million, where values greater than or equal to median = 1 and values less than median = 0 \n",
        "\n",
        "Output: \n",
        "\n",
        "1. 1915.5\n",
        "2. \n",
        "```\n",
        "0        0\n",
        "6        0\n",
        "22       0\n",
        "44       0\n",
        "59       0\n",
        "        ..\n",
        "14989    0\n",
        "14990    0\n",
        "14991    0\n",
        "14992    0\n",
        "14993    0\n",
        "Name: daily_vaccinations_per_million, Length: 9011, dtype: int64\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KznNiO1ooEcw"
      },
      "source": [
        "### Exercise 9 - Normalising total vaccinations   \n",
        "---\n",
        "The United Kingdom has been praised for its fast vaccine rollout. \n",
        "1. find the minimum total vaccinations for the United Kingdom \n",
        "2. save this value in a variable rounded down to an integer\n",
        "3. write a function to normalise total_vaccinations column so that all values less than the UK's min are 0 and all values greater than or equal to the UK's min are coded as 1 \n",
        "4. display the countries which total vaccinated is at the same rate or more than the UK\n",
        "\n",
        "Output:\n",
        "\n",
        "1. 1402432.0\n",
        "2. 1402432\n",
        "3. `df['people_vaccinated_per_hundred']` should output:\n",
        "```\n",
        "0        0\n",
        "6        0\n",
        "22       0\n",
        "44       0\n",
        "59       0\n",
        "        ..\n",
        "14989    0\n",
        "14990    0\n",
        "14991    0\n",
        "14992    0\n",
        "14993    0\n",
        "Name: total_vaccinations, Length: 9011, dtype: int64\n",
        "```\n",
        "4. \n",
        "```\n",
        "array(['Argentina', 'Australia', 'Austria', 'Azerbaijan', 'Bangladesh',\n",
        "       'Belgium', 'Brazil', 'Cambodia', 'Canada', 'Chile', 'China',\n",
        "       'Colombia', 'Czechia', 'Denmark', 'Dominican Republic', 'England',\n",
        "       'Finland', 'France', 'Germany', 'Greece', 'Hong Kong', 'Hungary',\n",
        "       'India', 'Indonesia', 'Ireland', 'Israel', 'Italy', 'Japan',\n",
        "       'Kazakhstan', 'Malaysia', 'Mexico', 'Morocco', 'Nepal',\n",
        "       'Netherlands', 'Norway', 'Pakistan', 'Peru', 'Philippines',\n",
        "       'Poland', 'Portugal', 'Qatar', 'Romania', 'Russia', 'Saudi Arabia',\n",
        "       'Scotland', 'Serbia', 'Singapore', 'Slovakia', 'South Korea',\n",
        "       'Spain', 'Sweden', 'Switzerland', 'Thailand', 'Turkey',\n",
        "       'United Arab Emirates', 'United Kingdom', 'United States',\n",
        "       'Uruguay', 'Wales'], dtype=object)\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tDRE0Nr1jGA"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9upnqmDO9Yko"
      },
      "source": [
        "### Exercise 10 - create new series of total vaccinations for each manufacturer\n",
        "---\n",
        "\n",
        "To create a new column in your dataframe:\n",
        "\n",
        "`df['new_column'] = ...`\n",
        "\n",
        "For example:\n",
        "\n",
        "* to duplicate an existing column\n",
        "  * `df['new_column'] = df['old_column']`\n",
        "* to add two columns together \n",
        "  * `df['new_column'] = df['column1'] + df['column2']`\n",
        "* to make a percentages column \n",
        "  * `df['new_column'] = (df['column1']/df['column1].sum()) * 100`\n",
        "\n",
        "  \n",
        "1. read data from 'by_manufacturer' sheet from Covid data \n",
        "2. find the sum of total vaccinations for each manufacturer\n",
        "3. create a new column that has the total vaccinations as a percentage of the overall sum of total vaccinations \n",
        "4. find the median percentage \n",
        "5. create a new column called 'normalised_percentages' which duplicates the percentages column\n",
        "6. normalise the normalised_percentages column so that any values greater than or equal to the median percentage = 1 and any lesser than = 0 \n",
        "\n",
        "\n",
        "Output:\n",
        "\n",
        "1.\n",
        "2. \n",
        "```\n",
        "vaccine\n",
        "Johnson&Johnson        264839828\n",
        "Moderna               5548036383\n",
        "Oxford/AstraZeneca     539433203\n",
        "Pfizer/BioNTech       8690461304\n",
        "Sinovac                604660293\n",
        "Name: total_vaccinations, dtype: int64\n",
        "```\n",
        "3. \n",
        "```\n",
        "\tlocation\tdate\tvaccine\ttotal_vaccinations\tpercentages\n",
        "0\tChile\t2020-12-24\tPfizer/BioNTech\t420\t0.000003\n",
        "1\tChile\t2020-12-25\tPfizer/BioNTech\t5198\t0.000033\n",
        "2\tChile\t2020-12-26\tPfizer/BioNTech\t8338\t0.000053\n",
        "3\tChile\t2020-12-27\tPfizer/BioNTech\t8649\t0.000055\n",
        "4\tChile\t2020-12-28\tPfizer/BioNTech\t8649\t0.000055\n",
        "...\t...\t...\t...\t...\t...\n",
        "3291\tUnited States\t2021-05-01\tModerna\t105947940\t0.677095\n",
        "3292\tUnited States\t2021-05-01\tPfizer/BioNTech\t129013657\t0.824504\n",
        "3293\tUnited States\t2021-05-02\tJohnson&Johnson\t8374395\t0.053519\n",
        "3294\tUnited States\t2021-05-02\tModerna\t106780082\t0.682413\n",
        "3295\tUnited States\t2021-05-02\tPfizer/BioNTech\t130252779\t0.832423\n",
        "3296 rows × 5 columns\n",
        "```\n",
        "4. 0.0011110194374896931\n",
        "5. \n",
        "6. \n",
        "```\n",
        "\tlocation\tdate\tvaccine\ttotal_vaccinations\tpercentages\tnormalise\tnormalised\n",
        "0\tChile\t2020-12-24\tPfizer/BioNTech\t420\t0.000003\t0.000003\t0\n",
        "1\tChile\t2020-12-25\tPfizer/BioNTech\t5198\t0.000033\t0.000033\t0\n",
        "2\tChile\t2020-12-26\tPfizer/BioNTech\t8338\t0.000053\t0.000053\t0\n",
        "3\tChile\t2020-12-27\tPfizer/BioNTech\t8649\t0.000055\t0.000055\t0\n",
        "4\tChile\t2020-12-28\tPfizer/BioNTech\t8649\t0.000055\t0.000055\t0\n",
        "...\t...\t...\t...\t...\t...\t...\t...\n",
        "3291\tUnited States\t2021-05-01\tModerna\t105947940\t0.677095\t0.677095\t1\n",
        "3292\tUnited States\t2021-05-01\tPfizer/BioNTech\t129013657\t0.824504\t0.824504\t1\n",
        "3293\tUnited States\t2021-05-02\tJohnson&Johnson\t8374395\t0.053519\t0.053519\t1\n",
        "3294\tUnited States\t2021-05-02\tModerna\t106780082\t0.682413\t0.682413\t1\n",
        "3295\tUnited States\t2021-05-02\tPfizer/BioNTech\t130252779\t0.832423\t0.832423\t1\n",
        "3296 rows × 7 columns\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXZELaz9B3H3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
